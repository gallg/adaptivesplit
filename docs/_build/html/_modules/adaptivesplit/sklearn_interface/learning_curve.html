<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>adaptivesplit.sklearn_interface.learning_curve &mdash; AdaptiveSplit 0.0.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> AdaptiveSplit
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"></div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">AdaptiveSplit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">adaptivesplit.sklearn_interface.learning_curve</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for adaptivesplit.sklearn_interface.learning_curve</h1><div class="highlight"><pre>
<span></span><span class="c1">#extends basse.learning_curve with scikit-learn functionality</span>
<span class="kn">from</span> <span class="nn">..base.learning_curve</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">is_regressor</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">check_cv</span><span class="p">,</span> <span class="n">check_scoring</span>
<span class="kn">from</span> <span class="nn">.resampling</span> <span class="kn">import</span> <span class="n">SubSampleCV</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">def lc_keymaker(estimator, X, y, ns, cv=5, cv_stat=np.mean, dummy_estimator=None,</span>
<span class="sd">                shuffle=-1, replacement=False, scoring=None, verbose=True, n_jobs=None, random_state=None,</span>
<span class="sd">                *args, **kwargs):</span>
<span class="sd">    # resolve nans:</span>
<span class="sd">    if dummy_estimator is None:</span>
<span class="sd">        dummy_estimator = &#39;default&#39;</span>
<span class="sd">    if scoring is None:</span>
<span class="sd">        scoring = &#39;default&#39;</span>
<span class="sd">    if n_jobs is None:</span>
<span class="sd">        n_jobs = &#39;default&#39;</span>
<span class="sd">    if random_state is None:</span>
<span class="sd">        random_state = np.random.normal()</span>

<span class="sd">    return str(estimator), str(X), str(y), str(ns), str(cv), str(</span>
<span class="sd">        cv_stat), dummy_estimator, shuffle, replacement, scoring, verbose, n_jobs, random_state</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># factory function for sklearn</span>
<span class="c1"># @cached(max_size=64, custom_key_maker=lc_keymaker)</span>
<div class="viewcode-block" id="calculate_learning_curve"><a class="viewcode-back" href="../../../adaptivesplit.sklearn_interface.html#adaptivesplit.sklearn_interface.learning_curve.calculate_learning_curve">[docs]</a><span class="k">def</span> <span class="nf">calculate_learning_curve</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_sizes</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">cv_stat</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">dummy_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">power_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate learning curve on training and test data. Also generates a learning curve for baseline performance using dummy estimators.</span>

<span class="sd">    Args:</span>
<span class="sd">        estimator (estimator object): </span>
<span class="sd">            Estimator object. A object of that type is instantiated for each grid point.</span>
<span class="sd">            This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score</span>
<span class="sd">            function, or scoring must be passed. If it is e.g. a GridSearchCV then nested cv is performed (recommended).</span>
<span class="sd">        X (numpy.ndarray or pandas.DataFrame):</span>
<span class="sd">            array-like of shape (n_samples, n_features). The data to fit as in scikit-learn. Can be a numpy array or </span>
<span class="sd">            pandas DataFrame.</span>
<span class="sd">        y (numpy.ndarray or pandas.Series):</span>
<span class="sd">            array-like of shape (n_samples,) or (n_samples, n_outputs), default=None</span>
<span class="sd">            The target variable to try to predict in the case of supervised learning, as in scikit-learn.</span>
<span class="sd">        sample_sizes (int or list of int):</span>
<span class="sd">            sample sizes to calculate the learning curve.</span>
<span class="sd">        stratify (int):</span>
<span class="sd">            For classification tasks. If not None, use stratified sampling to account for class labels imbalance.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        cv (int, cross-validation generator or an iterable):</span>
<span class="sd">            Determines the cross-validation splitting strategy, as in scikit-learn. Possible inputs for cv are:</span>
<span class="sd">            </span>
<span class="sd">            - None, to use the default 5-fold cross validation,</span>
<span class="sd">            - int, to specify the number of folds in a (Stratified)KFold,</span>
<span class="sd">            - CV splitter,</span>
<span class="sd">            - An iterable yielding (train, test) splits as arrays of indices.</span>
<span class="sd">            </span>
<span class="sd">            For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold </span>
<span class="sd">            is used. In all other cases, K-Fold is used. These splitters are instantiated with shuffle=False so </span>
<span class="sd">            the splits will be the same across calls. Defaults to 5.</span>
<span class="sd">        cv_stat (callable):</span>
<span class="sd">            Function for aggregating cross-validation-wise scores. Defaults to numpy.mean.</span>
<span class="sd">        dummy_estimator (estimator object):</span>
<span class="sd">            A scikit-learn-like dummy estimator to evaluate baseline performance.</span>
<span class="sd">            If None, either DummyClassifier() or DummyRegressor() are used, based on &#39;estimator&#39;s type.</span>
<span class="sd">        num_samples (int):</span>
<span class="sd">            Number of iterations to shuffle data before determining subsamples.</span>
<span class="sd">            The first iteration (index 0) is ALWAYS unshuffled (num_samples=1 implies no resampling at all, default).</span>
<span class="sd">        power_estimator (callable):</span>
<span class="sd">            Callable must be a power_estimator function, see the &#39;create_power_estimator*&#39; factory functions.</span>
<span class="sd">            If None, power curve is not calculated. Defaults to None.</span>
<span class="sd">        scoring (str, callable, list, tuple or dict):</span>
<span class="sd">            Scikit-learn-like score to evaluate the performance of the cross-validated model on the test set.</span>
<span class="sd">            If scoring represents a single score, one can use:</span>

<span class="sd">            - a single string (see The scoring parameter: defining model evaluation rules);</span>
<span class="sd">            - a callable (see Defining your scoring strategy from metric functions) that returns a single value.</span>

<span class="sd">            If scoring represents multiple scores, one can use:</span>

<span class="sd">            - a list or tuple of unique strings;</span>
<span class="sd">            - a callable returning a dictionary where the keys are the metric names and the values are the metric scores;</span>
<span class="sd">            - a dictionary with metric names as keys and callables a values.</span>

<span class="sd">            If None, the estimatorâ€™s score method is used. Defaults to None.</span>
<span class="sd">        verbose (bool):</span>
<span class="sd">            If not False, prints progress. Defaults to True.</span>
<span class="sd">        n_jobs (int):</span>
<span class="sd">            Number of jobs to run in parallel. Defaults to None.</span>
<span class="sd">            Training the estimator and computing the score are parallelized over the cross-validation splits.</span>
<span class="sd">            None means 1 unless in a joblib.parallel_backend context. -1 means using all processors.</span>
<span class="sd">        random_state (int):</span>
<span class="sd">            Controls the randomness of the bootstrapping of the samples used when building sub-samples </span>
<span class="sd">            (if shuffle!=-1). Defaults to None.</span>
<span class="sd">        *args: </span>
<span class="sd">            Extra parameters passed to sklearn.model_selection.cross_validate.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Extra keyword parameters passed to sklearn.model_selection.cross_validate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        lc_train (adaptivesplit.base.learning_curve.LearningCurve object): </span>
<span class="sd">            Learning curve calculated on training data.</span>
<span class="sd">        lc_test (adaptivesplit.base.learning_curve.LearningCurve object):</span>
<span class="sd">            Learning curve calculated on test data.</span>
<span class="sd">        lc_dummy (adaptivesplit.base.learning_curve.LearningCurve object):</span>
<span class="sd">            Learning curve calculated using the dummy estimator. It estimates baseline learning performance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="c1"># squeezing avoids errors with some datasets;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="n">inc</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">())</span> <span class="o">/</span> <span class="n">sample_sizes</span>
        <span class="n">sample_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(),</span> <span class="n">stop</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">inc</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">inc</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">scoring</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scoring</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dummy_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
            <span class="n">dummy_estimator</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">()</span> <span class="c1"># strategy=&#39;stratified&#39;?</span>
        <span class="k">elif</span> <span class="n">is_regressor</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
            <span class="n">dummy_estimator</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Estimator can only be classifier or regressor.&quot;</span><span class="p">)</span>

    <span class="n">subsampler</span> <span class="o">=</span> <span class="n">SubSampleCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                             <span class="n">dummy_estimator</span><span class="o">=</span><span class="n">dummy_estimator</span><span class="p">,</span>
                             <span class="n">sample_size</span><span class="o">=</span><span class="n">sample_sizes</span><span class="p">,</span>
                             <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                             <span class="n">cv_stat</span><span class="o">=</span><span class="n">cv_stat</span><span class="p">,</span>
                             <span class="n">power_estimator</span><span class="o">=</span><span class="n">power_estimator</span><span class="p">,</span>
                             <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                             <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                             <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span>
                             <span class="p">)</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="n">subsampler</span><span class="o">.</span><span class="n">subsample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">stratify</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># return the stuff</span>
    <span class="n">lc_train</span> <span class="o">=</span> <span class="n">LearningCurve</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">stats</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
                             <span class="n">ns</span><span class="o">=</span><span class="n">sample_sizes</span><span class="p">,</span>
                             <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                             <span class="n">description</span><span class="o">=</span><span class="p">{</span>
                                 <span class="s2">&quot;shuffles&quot;</span><span class="p">:</span> <span class="n">num_samples</span><span class="p">},</span>
                             <span class="n">curve_type</span><span class="o">=</span><span class="s2">&quot;train&quot;</span>
                             <span class="p">)</span>

    <span class="n">lc_test</span> <span class="o">=</span> <span class="n">LearningCurve</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">stats</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
                            <span class="n">ns</span><span class="o">=</span><span class="n">sample_sizes</span><span class="p">,</span>
                            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                            <span class="n">description</span><span class="o">=</span><span class="p">{</span>
                                <span class="s2">&quot;shuffles&quot;</span><span class="p">:</span> <span class="n">num_samples</span><span class="p">},</span>
                            <span class="n">curve_type</span><span class="o">=</span><span class="s2">&quot;test&quot;</span>
                            <span class="p">)</span>

    <span class="n">lc_dummy</span> <span class="o">=</span> <span class="n">LearningCurve</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">stats</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
                             <span class="n">ns</span><span class="o">=</span><span class="n">sample_sizes</span><span class="p">,</span>
                             <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                             <span class="n">description</span><span class="o">=</span><span class="p">{</span>
                                 <span class="s2">&quot;shuffles&quot;</span><span class="p">:</span> <span class="n">num_samples</span><span class="p">},</span>
                             <span class="n">curve_type</span><span class="o">=</span><span class="s2">&quot;dummy&quot;</span>
                             <span class="p">)</span>

    <span class="k">if</span> <span class="n">power_estimator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lc_power</span> <span class="o">=</span> <span class="n">LearningCurve</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">stats</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
                                 <span class="n">ns</span><span class="o">=</span><span class="n">sample_sizes</span><span class="p">,</span>
                                 <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                                 <span class="n">description</span><span class="o">=</span><span class="p">{</span>
                                     <span class="s2">&quot;shuffles&quot;</span><span class="p">:</span> <span class="n">num_samples</span><span class="p">},</span>
                                 <span class="n">curve_type</span><span class="o">=</span><span class="s2">&quot;power&quot;</span>
                                 <span class="p">)</span>
        <span class="k">return</span> <span class="n">lc_train</span><span class="p">,</span> <span class="n">lc_test</span><span class="p">,</span> <span class="n">lc_dummy</span><span class="p">,</span> <span class="n">lc_power</span>

    <span class="k">return</span> <span class="n">lc_train</span><span class="p">,</span> <span class="n">lc_test</span><span class="p">,</span> <span class="n">lc_dummy</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, G.Gallitto.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>